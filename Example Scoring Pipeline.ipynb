{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mTo sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code F9S8AKVV5 to authenticate.\u001b[0m\n",
      "[\n",
      "  {\n",
      "    \"cloudName\": \"AzureCloud\",\n",
      "    \"id\": \"63fc0c29-abe6-4170-b3bf-1cf85656b247\",\n",
      "    \"isDefault\": true,\n",
      "    \"name\": \"Visual Studio Enterprise\",\n",
      "    \"state\": \"Enabled\",\n",
      "    \"tenantId\": \"4e9843a2-758e-4a3b-8628-2fc4141091af\",\n",
      "    \"user\": {\n",
      "      \"name\": \"jmangia@me.com\",\n",
      "      \"type\": \"user\"\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "!az login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /home/nbuser/library/config.json\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Experiment, Run, Datastore\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found compute target. just use it. cpucluster\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "import os\n",
    "\n",
    "# choose a name for your cluster\n",
    "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"cpucluster\")\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('found compute target. just use it. ' + compute_name)\n",
    "else:\n",
    "    print('Error getting Compute target...')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Blob datastores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workspaceblobstore AzureBlob\n",
      "workspacefilestore AzureFile\n",
      "challenge1 AzureBlob\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<azureml.data.azure_storage_datastore.AzureBlobDatastore at 0x7ff3d5d2d978>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list all datastores registered in current workspace\n",
    "datastores = ws.datastores\n",
    "for name, ds in datastores.items():\n",
    "    print(name, ds.datastore_type)\n",
    "    \n",
    "#def_data_store = ws.get_default_datastore() \n",
    "def_data_store = Datastore(ws, \"challenge1\")\n",
    "def_data_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.pipeline.core import PipelineData\n",
    "\n",
    "input_file_name = \"input.json\"\n",
    "\n",
    "input_data_reference = DataReference(\n",
    "    datastore=def_data_store,\n",
    "    data_reference_name=\"input_data\",\n",
    "    path_on_datastore=input_file_name)\n",
    "\n",
    "output_data = PipelineData(\n",
    "    \"output_data\",\n",
    "    datastore=def_data_store,\n",
    "    output_name=\"output_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Fake JSON input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temp file = ./input.json\n",
      "\n",
      "Uploading to Blob storage as blob./input.json\n",
      "Uploading ./input.json\n",
      "Uploaded ./input.json, 1 files out of an estimated total of 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_challenge1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_path = os.path.join(\".\", input_file_name)\n",
    "with open(local_path, 'w') as json_file:\n",
    "    json_file.write('{ \"radius\" : 4 }')\n",
    "\n",
    "print(\"Temp file = \" + local_path)\n",
    "print(\"\\nUploading to Blob storage as blob\" + local_path)\n",
    "\n",
    "def_data_store.upload_files(files=[local_path],\n",
    "                            target_path='.',\n",
    "                            overwrite=True,\n",
    "                            show_progress=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Model (fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run completed\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Experiment, Run\n",
    "import math, random, pickle\n",
    "\n",
    "experiment = Experiment(workspace = ws, name = \"model_creation\")\n",
    "run = experiment.start_logging()\n",
    "\n",
    "pi_counter = 0\n",
    "n_iter = 100000\n",
    "\n",
    "# Log total number of iterations\n",
    "run.log(\"Number of iterations\",n_iter)\n",
    "\n",
    "for i in range(1,n_iter):\n",
    "    # Monte Carlo step to update estimate\n",
    "    x = random.random()\n",
    "    y = random.random()\n",
    "    if x*x + y*y < 1.0:\n",
    "        pi_counter += 1\n",
    "    pi_estimate = 4.0*pi_counter / i\n",
    "    \n",
    "    # Log convergence every 10000 iterations\n",
    "    if i%10000==0:\n",
    "        error = math.pi-pi_estimate\n",
    "        run.log(\"Pi estimate\",pi_estimate)\n",
    "        run.log(\"Error\",error)\n",
    "\n",
    "# Log final results\n",
    "run.log(\"Final estimate\",pi_estimate)\n",
    "run.log(\"Final error\",math.pi-pi_estimate)\n",
    "\n",
    "# Write file containing pi value into run history\n",
    "with open(\"pi_estimate.txt\",\"wb\") as f:\n",
    "    pickle.dump(str(pi_estimate),f)\n",
    "run.upload_file(name = 'outputs/pi_estimate.txt', path_or_stream = './pi_estimate.txt')\n",
    "\n",
    "# Complete tracking and get link to details\n",
    "run.complete()\n",
    "print(\"Run completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>model_creation</td><td>0c6bd594-0e88-4bae-ac52-52fae72c37ea</td><td></td><td>Completed</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/63fc0c29-abe6-4170-b3bf-1cf85656b247/resourceGroups/MLHack/providers/Microsoft.MachineLearningServices/workspaces/challenge1/experiments/model_creation/runs/0c6bd594-0e88-4bae-ac52-52fae72c37ea\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run.Run?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: model_creation,\n",
       "Id: 0c6bd594-0e88-4bae-ac52-52fae72c37ea,\n",
       "Type: None,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"fake_model\"\n",
    "model = run.register_model(model_name = model_name, model_path = \"outputs/pi_estimate.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting batch_score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile batch_score.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "from azureml.core import Run\n",
    "from azureml.core.model import Model\n",
    "import pickle, json\n",
    "\n",
    "def main():\n",
    "    run = Run.get_context()\n",
    "    run.log(\"start batch score\", 1)\n",
    "\n",
    "    print(\"In batch_score.py\")\n",
    "\n",
    "    parser = argparse.ArgumentParser(\"scoring\")\n",
    "\n",
    "    parser.add_argument('--model_name', dest=\"model_name\", required=True)\n",
    "    parser.add_argument(\"--input\", type=str, help=\"input data\", required=True)\n",
    "    parser.add_argument(\"--output\", type=str, help=\"output data\", required=True)\n",
    "    parser.add_argument(\"--param1\", type=str, help=\"param 1\")\n",
    "\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    print(\"Model: %s\" % args.model_name)\n",
    "    print(\"Input: %s\" % args.input)\n",
    "    print(\"Output: %s\" % args.output)\n",
    "    print(\"Param1: %s\" % args.param1)\n",
    "\n",
    "    run.log(\"start batch score\", 2)\n",
    "\n",
    "    # Get the Model\n",
    "    global pi_estimate\n",
    "    model_path = Model.get_model_path(model_name = args.model_name)\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        pi_estimate = float(pickle.load(f))\n",
    "\n",
    "        \n",
    "    # Get the input Data\n",
    "    with open(args.input) as json_file:  \n",
    "        data = json.load(json_file)\n",
    "    radius = data[\"radius\"]\n",
    "    \n",
    "    \n",
    "    # Use the Model\n",
    "    area = pi_estimate * radius**2\n",
    "    run.log(\"Radius: %s\" % radius, 1)\n",
    "    run.log(\"Area: %s\" % area, 1)\n",
    "    print(\"Radius: %s\" % radius)\n",
    "    print(\"Area: %s\" % area)\n",
    "\n",
    "    \n",
    "    # create output directory if it does not exist\n",
    "    os.makedirs(args.output, exist_ok=True)\n",
    "\n",
    "    \n",
    "    # Save output on blob storage\n",
    "    out_filename = os.path.join(args.output, \"result.txt\")\n",
    "    with open(out_filename, \"w\") as result_file:\n",
    "        result_file.write(\"Area: %s\" % area)\n",
    "        result_file.flush()\n",
    "        \n",
    "    run.complete()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.steps.python_script_step import PythonScriptStep\n",
    "from azureml.pipeline.core.graph import PipelineParameter\n",
    "\n",
    "pipeline_param = PipelineParameter(\n",
    "  name=\"pipeline_arg\", \n",
    "  default_value=10)\n",
    "\n",
    "\n",
    "firstStep = PythonScriptStep(\n",
    "    script_name=\"batch_score.py\",\n",
    "    arguments=[\"--model_name\", model_name,\"--input\", input_data_reference, \"--output\", output_data, \"--param1\", pipeline_param],\n",
    "    inputs=[input_data_reference],\n",
    "    outputs=[output_data],\n",
    "    compute_target=compute_target,\n",
    "    source_directory=\".\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "scoring_pipeline = Pipeline(workspace=ws, steps=[firstStep])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step batch_score.py [359d5fd3][a05c6dc6-f08a-4df8-8028-b71a4b57e220], (This step will run and generate new outputs)\n",
      "Using data reference input_data for StepId [99408c1d][509a91a8-26ed-4d52-878d-69a9dbbed28c], (Consumers of this data are eligible to reuse prior runs.)\n",
      "Submitted pipeline run: ca6a985e-3c4c-4bd1-90ba-faf0bfa68655\n",
      "RunId: ca6a985e-3c4c-4bd1-90ba-faf0bfa68655\n",
      "Link to Portal: https://mlworkspace.azure.ai/portal/subscriptions/63fc0c29-abe6-4170-b3bf-1cf85656b247/resourceGroups/MLHack/providers/Microsoft.MachineLearningServices/workspaces/challenge1/experiments/Score_Pipeline_Experiment/runs/ca6a985e-3c4c-4bd1-90ba-faf0bfa68655\n",
      "Status: Running\n",
      ".......\n",
      "Status: Finished\n",
      "{'runId': 'ca6a985e-3c4c-4bd1-90ba-faf0bfa68655', 'status': 'Completed', 'startTimeUtc': '2019-04-22T23:36:11.235703Z', 'endTimeUtc': '2019-04-22T23:36:59.172586Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': None, 'runType': 'HTTP', 'azureml.parameters': '{\"pipeline_arg\":\"10\"}'}, 'logFiles': {'logs/azureml/executionlogs.txt': 'https://challenge12193430701.blob.core.windows.net/azureml/ExperimentRun/dcid.ca6a985e-3c4c-4bd1-90ba-faf0bfa68655/logs/azureml/executionlogs.txt?sv=2018-03-28&sr=b&sig=GUtT2zLppbvcHWlbuQOf4YOF%2Fh9G5JJS40HqiYd9Xms%3D&st=2019-04-22T23%3A27%3A01Z&se=2019-04-23T07%3A37%3A01Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://challenge12193430701.blob.core.windows.net/azureml/ExperimentRun/dcid.ca6a985e-3c4c-4bd1-90ba-faf0bfa68655/logs/azureml/stdoutlogs.txt?sv=2018-03-28&sr=b&sig=9OnToPACfja6hF%2FDjKmHwlT3aSd%2BwikXefJ3yGtwZIw%3D&st=2019-04-22T23%3A27%3A01Z&se=2019-04-23T07%3A37%3A01Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://challenge12193430701.blob.core.windows.net/azureml/ExperimentRun/dcid.ca6a985e-3c4c-4bd1-90ba-faf0bfa68655/logs/azureml/stderrlogs.txt?sv=2018-03-28&sr=b&sig=k8N4tHpfiLpxfJjoAWU1A%2BS8sIDz1qva4JxWxdEnID8%3D&st=2019-04-22T23%3A27%3A01Z&se=2019-04-23T07%3A37%3A01Z&sp=r'}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Submit the pipeline to be run\n",
    "pipeline_run1 = Experiment(ws, \"Score_Pipeline_Experiment\").submit(scoring_pipeline, show_output=True)\n",
    "pipeline_run1.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline1.publish(name=\"Scoring Pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schedule Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Setup"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!az login",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "\u001b[33mTo sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code FH2LVFFLY to authenticate.\u001b[0m\n[\n  {\n    \"cloudName\": \"AzureCloud\",\n    \"id\": \"63fc0c29-abe6-4170-b3bf-1cf85656b247\",\n    \"isDefault\": true,\n    \"name\": \"Visual Studio Enterprise\",\n    \"state\": \"Enabled\",\n    \"tenantId\": \"4e9843a2-758e-4a3b-8628-2fc4141091af\",\n    \"user\": {\n      \"name\": \"jmangia@me.com\",\n      \"type\": \"user\"\n    }\n  }\n]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core import Workspace, Experiment, Run, Datastore\nws = Workspace.from_config()",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Warning: Falling back to use azure cli login credentials.\nIf you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\nPlease refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Found the config file in: /home/nbuser/library/config.json\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.compute import AmlCompute\nfrom azureml.core.compute import ComputeTarget\nimport os\n\n# choose a name for your cluster\ncompute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"cpucluster\")\n\nif compute_name in ws.compute_targets:\n    compute_target = ws.compute_targets[compute_name]\n    if compute_target and type(compute_target) is AmlCompute:\n        print('found compute target. just use it. ' + compute_name)\nelse:\n    print('Error getting Compute target...')\n",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "found compute target. just use it. cpucluster\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Connect to Blob datastores"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#list all datastores registered in current workspace\ndatastores = ws.datastores\nfor name, ds in datastores.items():\n    print(name, ds.datastore_type)\n    \n#def_data_store = ws.get_default_datastore() \ndef_data_store = Datastore(ws, \"challenge1\")\ndef_data_store",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "workspaceblobstore AzureBlob\nworkspacefilestore AzureFile\nchallenge1 AzureBlob\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "<azureml.data.azure_storage_datastore.AzureBlobDatastore at 0x7f569b7842e8>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.data.data_reference import DataReference\nfrom azureml.pipeline.core import PipelineData\n\ninput_data_reference = DataReference(\n    datastore=def_data_store,\n    data_reference_name=\"test_data\",\n    path_on_datastore=\"microsoft-malware-prediction/test.csv\")\n\noutput_data = PipelineData(\n    \"output_data1\",\n    datastore=def_data_store,\n    output_name=\"output_data1\")",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Create the Model (fake)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core import Workspace, Experiment, Run\nimport math, random, pickle\n\nexperiment = Experiment(workspace = ws, name = \"model_creation\")\nrun = experiment.start_logging()\n\npi_counter = 0\nn_iter = 100000\n\n# Log total number of iterations\nrun.log(\"Number of iterations\",n_iter)\n\nfor i in range(1,n_iter):\n    # Monte Carlo step to update estimate\n    x = random.random()\n    y = random.random()\n    if x*x + y*y < 1.0:\n        pi_counter += 1\n    pi_estimate = 4.0*pi_counter / i\n    \n    # Log convergence every 10000 iterations\n    if i%10000==0:\n        error = math.pi-pi_estimate\n        run.log(\"Pi estimate\",pi_estimate)\n        run.log(\"Error\",error)\n\n# Log final results\nrun.log(\"Final estimate\",pi_estimate)\nrun.log(\"Final error\",math.pi-pi_estimate)\n\n# Write file containing pi value into run history\nwith open(\"pi_estimate.txt\",\"wb\") as f:\n    pickle.dump(str(pi_estimate),f)\nrun.upload_file(name = 'outputs/pi_estimate.txt', path_or_stream = './pi_estimate.txt')\n\n# Complete tracking and get link to details\nrun.complete()\nprint(\"Run completed\")",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Run completed\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "run",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>model_creation</td><td>6b9dd51b-f763-431d-990b-6f78f9f1ada5</td><td></td><td>Completed</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/63fc0c29-abe6-4170-b3bf-1cf85656b247/resourceGroups/MLHack/providers/Microsoft.MachineLearningServices/workspaces/challenge1/experiments/model_creation/runs/6b9dd51b-f763-431d-990b-6f78f9f1ada5\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run.Run?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>",
            "text/plain": "Run(Experiment: model_creation,\nId: 6b9dd51b-f763-431d-990b-6f78f9f1ada5,\nType: None,\nStatus: Completed)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "model_name = \"fake_model\"\nmodel = run.register_model(model_name = model_name, model_path = \"outputs/pi_estimate.txt\")",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Batch Scoring"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%writefile batch_score.py\n\nimport argparse\nimport os\nfrom azureml.core import Run\nfrom azureml.core.model import Model\nimport pickle, json\n\ndef main():\n    run = Run.get_context()\n    run.log(\"start batch score\", 1)\n\n    print(\"In batch_score.py\")\n\n    parser = argparse.ArgumentParser(\"scoring\")\n\n    parser.add_argument('--model_name', dest=\"model_name\", required=True)\n    parser.add_argument(\"--input\", type=str, help=\"input data\", required=True)\n    parser.add_argument(\"--output\", type=str, help=\"output data\", required=True)\n    parser.add_argument(\"--param1\", type=str, help=\"param 1\")\n\n\n    args = parser.parse_args()\n\n    print(\"Model: %s\" % args.model_name)\n    print(\"Input: %s\" % args.input)\n    print(\"Output: %s\" % args.output)\n    print(\"Param1: %s\" % args.param1)\n\n    run.log(\"start batch score\", 2)\n\n    \n    global pi_estimate\n    model_path = Model.get_model_path(model_name = args.model_name)\n    with open(model_path, \"rb\") as f:\n        pi_estimate = float(pickle.load(f))\n\n    radius = 3\n    area = pi_estimate * radius**2\n\n    run.log(\"Radius: %s\" % radius, 1)\n    run.log(\"Area: %s\" % area, 1)\n\n    print(\"Radius: %s\" % radius)\n    print(\"Area: %s\" % area)\n\n    run.complete()\n\n\nif __name__ == \"__main__\":\n    main()",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Overwriting batch_score.py\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Create Pipeline"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.pipeline.steps.python_script_step import PythonScriptStep\nfrom azureml.pipeline.core.graph import PipelineParameter\n\npipeline_param = PipelineParameter(\n  name=\"pipeline_arg\", \n  default_value=10)\n\n\nfirstStep = PythonScriptStep(\n    script_name=\"batch_score.py\",\n    arguments=[\"--model_name\", model_name,\"--input\", input_data_reference, \"--output\", output_data, \"--param1\", pipeline_param],\n    inputs=[input_data_reference],\n    outputs=[output_data],\n    compute_target=compute_target,\n    source_directory=\".\"\n)",
      "execution_count": 29,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.pipeline.core import Pipeline\n\nscoring_pipeline = Pipeline(workspace=ws, steps=[firstStep])",
      "execution_count": 30,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Test Pipeline"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Submit the pipeline to be run\npipeline_run1 = Experiment(ws, \"Score_Pipeline_Experiment\").submit(scoring_pipeline, show_output=True)\npipeline_run1.wait_for_completion()",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Created step batch_score.py [c3d9d1ea][0b7eb841-f85b-47ff-9e51-06dcde03904b], (This step will run and generate new outputs)\nUsing data reference test_data for StepId [60111503][cfe7239c-0f2e-4945-943e-a824ce376816], (Consumers of this data are eligible to reuse prior runs.)\nSubmitted pipeline run: c977862a-c22e-4227-802e-65282ce6b42c\nRunId: c977862a-c22e-4227-802e-65282ce6b42c\nLink to Portal: https://mlworkspace.azure.ai/portal/subscriptions/63fc0c29-abe6-4170-b3bf-1cf85656b247/resourceGroups/MLHack/providers/Microsoft.MachineLearningServices/workspaces/challenge1/experiments/Score_Pipeline_Experiment/runs/c977862a-c22e-4227-802e-65282ce6b42c\nStatus: Running\n.......\nStatus: Finished\n{'runId': 'c977862a-c22e-4227-802e-65282ce6b42c', 'status': 'Completed', 'startTimeUtc': '2019-04-22T22:14:12.736251Z', 'endTimeUtc': '2019-04-22T22:14:59.878873Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': None, 'runType': 'HTTP', 'azureml.parameters': '{\"pipeline_arg\":\"10\"}'}, 'logFiles': {'logs/azureml/stderrlogs.txt': 'https://challenge12193430701.blob.core.windows.net/azureml/ExperimentRun/dcid.c977862a-c22e-4227-802e-65282ce6b42c/logs/azureml/stderrlogs.txt?sv=2018-03-28&sr=b&sig=1Og9ZGvx1JzrM0LBuxMJJbI8MuLK2YfC8PAXgKGaEqU%3D&st=2019-04-22T22%3A05%3A01Z&se=2019-04-23T06%3A15%3A01Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://challenge12193430701.blob.core.windows.net/azureml/ExperimentRun/dcid.c977862a-c22e-4227-802e-65282ce6b42c/logs/azureml/stdoutlogs.txt?sv=2018-03-28&sr=b&sig=z%2FHzDhHWa13f2%2BJ9aOUZJ4e5wPJe%2B9CuI7oSy9Zg0M8%3D&st=2019-04-22T22%3A05%3A01Z&se=2019-04-23T06%3A15%3A01Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://challenge12193430701.blob.core.windows.net/azureml/ExperimentRun/dcid.c977862a-c22e-4227-802e-65282ce6b42c/logs/azureml/executionlogs.txt?sv=2018-03-28&sr=b&sig=IBdq2FDBVx1aROnLyHRWZlaJyG1cg0zyhiIOTlsZiWk%3D&st=2019-04-22T22%3A05%3A01Z&se=2019-04-23T06%3A15%3A01Z&sp=r'}}\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 31,
          "data": {
            "text/plain": "'Finished'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Publish Pipeline"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "pipeline1.publish(name=\"Scoring Pipeline\")",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Created step batch_score.py [a0ed9780][0b7eb841-f85b-47ff-9e51-06dcde03904b], (This step is eligible to reuse a previous run's output)\nUsing data reference test_data for StepId [3a5b31ce][cfe7239c-0f2e-4945-943e-a824ce376816], (Consumers of this data are eligible to reuse prior runs.)\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 32,
          "data": {
            "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>Scoring Pipeline</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/63fc0c29-abe6-4170-b3bf-1cf85656b247/resourceGroups/MLHack/providers/Microsoft.MachineLearningServices/workspaces/challenge1/pipelines/ab90bb13-18bd-44f3-ad96-3173ef594081\" target=\"_blank\" rel=\"noopener\">ab90bb13-18bd-44f3-ad96-3173ef594081</a></td><td>Active</td><td><a href=\"https://westus2.aether.ms/api/v1.0/subscriptions/63fc0c29-abe6-4170-b3bf-1cf85656b247/resourceGroups/MLHack/providers/Microsoft.MachineLearningServices/workspaces/challenge1/PipelineRuns/PipelineSubmit/ab90bb13-18bd-44f3-ad96-3173ef594081\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>",
            "text/plain": "Pipeline(Name: Scoring Pipeline,\nId: ab90bb13-18bd-44f3-ad96-3173ef594081,\nStatus: Active,\nEndpoint: https://westus2.aether.ms/api/v1.0/subscriptions/63fc0c29-abe6-4170-b3bf-1cf85656b247/resourceGroups/MLHack/providers/Microsoft.MachineLearningServices/workspaces/challenge1/PipelineRuns/PipelineSubmit/ab90bb13-18bd-44f3-ad96-3173ef594081)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Schedule Pipeline"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}